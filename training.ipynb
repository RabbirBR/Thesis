{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import glob, os, shutil\n",
    "\n",
    "import datetime, time\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Not Whale', 'Whale']\n",
    "learning_rates = [0.000001,0.0000001,0.00000001,0.000000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=180,   # randomly rotate between 0-180 degrees,\n",
    "    horizontal_flip=True, # allows to randomly flip the image Horizontally\n",
    "    vertical_flip=True    # allows to randomly flip the image Vertically\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Train',\n",
    "    batch_size = 2,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Test',\n",
    "    batch_size = 2,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "for i, learning_rate in enumerate(learning_rates):\n",
    "    clear_output()\n",
    "    print(str(learning_rate))\n",
    "    try:\n",
    "        details = {\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape = (224, 224, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = True\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            Activation('relu'),\n",
    "            layers.Dense(2, activation = 'softmax'),\n",
    "        ])\n",
    "\n",
    "        model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                      optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"model_checkpoints/mobile_net_V2_\"+str(learning_rate)+\"{epoch:02d}.h5\",\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks = [checkpoint],\n",
    "                            verbose = 1)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Time Taken: {:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "        model.save_weights(filepath = \"trained_models/mobile_net_V2_\"+str(learning_rate)+\".h5\")\n",
    "        pickle.dump( history.history, open(\"trained_models/mobile_net_V2_history_\"+str(learning_rate)+\".p\", \"wb\" ) )\n",
    "\n",
    "        details[\"model_path\"] = \"trained_models/mobile_net_V2_\"+str(learning_rate)+\".h5\"\n",
    "        details[\"history_path\"] = \"trained_models/mobile_net_V2_history_\"+str(learning_rate)+\".p\"\n",
    "        details[\"time_taken\"] = end-start\n",
    "        details[\"time_taken_hrs\"] = \"{:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds)\n",
    "\n",
    "        mobilenet_models.append(details)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mobilenet_models)\n",
    "df.to_csv(\"mobilenet_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XceptionV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Train',\n",
    "    batch_size = 2,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Test',\n",
    "    batch_size = 2,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "for i, learning_rate in enumerate([0.000001,0.00000001,0.000000001]):\n",
    "    clear_output()\n",
    "    print(learning_rate)\n",
    "    try:\n",
    "        details = {\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "\n",
    "        base_model = tf.keras.applications.Xception(input_shape = (224, 224, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = True\n",
    "\n",
    "        global_average_layer = layers.GlobalAveragePooling2D()\n",
    "\n",
    "        classes_layer = layers.Dense(2, activation = 'sigmoid')\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            classes_layer,\n",
    "        ])\n",
    "\n",
    "        model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                      optimizer = tf.keras.optimizers.RMSprop(lr = learning_rate), #0.00000001\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"model_checkpoints/xception_\"+str(learning_rate)+\"{epoch:02d}.h5\",\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks = [checkpoint],\n",
    "                            verbose = 1)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Time Taken: {:0>2}:{:0>2}:{:05.3f}\".format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        model.save_weights(filepath = \"trained_models/xception_\"+str(learning_rate)+\".h5\")\n",
    "        pickle.dump(history.history, open(\"trained_models/xception_history_\"+str(learning_rate)+\".p\", \"wb\" ))\n",
    "\n",
    "        details[\"model_path\"] = \"trained_models/xception_\"+str(learning_rate)+\".h5\"\n",
    "        details[\"history_path\"] = \"trained_models/xception_history_\"+str(learning_rate)+\".p\"\n",
    "        details[\"time_taken\"] = end-start\n",
    "        details[\"time_taken_hrs\"] = \"{:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds)\n",
    "\n",
    "        xception_models.append(details)\n",
    "        \n",
    "        df = pd.DataFrame(xception_models)\n",
    "        df.to_csv(\"xception_results.csv\", index = False)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet152-V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Train',\n",
    "    batch_size = 2,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Test',\n",
    "    batch_size = 2,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "for i, learning_rate in enumerate([0.000001,0.0000001,0.00000001]):\n",
    "    clear_output()\n",
    "    print(learning_rate)\n",
    "    try:\n",
    "        details = {\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "\n",
    "        base_model = tf.keras.applications.ResNet152V2(input_shape = (224, 224, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = True\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            Activation('relu'),\n",
    "            layers.Dense(2, activation = 'softmax'),\n",
    "        ])\n",
    "\n",
    "        model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                      optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"model_checkpoints/resnet152_V2_\"+str(learning_rate)+\"{epoch:02d}.h5\",\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks = [checkpoint],\n",
    "                            verbose = 1)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Time Taken: {:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "        model.save_weights(filepath = \"trained_models/resnet152_V2_\"+str(learning_rate)+\".h5\")\n",
    "        pickle.dump( history.history, open(\"trained_models/resnet152_V2_history_\"+str(learning_rate)+\".p\", \"wb\" ) )\n",
    "\n",
    "        details[\"model_path\"] = \"trained_models/resnet152_V2_\"+str(learning_rate)+\".h5\"\n",
    "        details[\"history_path\"] = \"trained_models/resnet152_V2_history_\"+str(learning_rate)+\".p\"\n",
    "        details[\"time_taken\"] = end-start\n",
    "        details[\"time_taken_hrs\"] = \"{:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds)\n",
    "\n",
    "        resnet_models.append(details)\n",
    "        \n",
    "        df = pd.DataFrame(resnet_models)\n",
    "        df.to_csv(\"resnet_results.csv\", index = False)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Train',\n",
    "    batch_size = 2,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory = 'dataset/Bioconsult/32_32/Test',\n",
    "    batch_size = 2,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "for i, learning_rate in enumerate([0.000000001]):\n",
    "    clear_output()\n",
    "    print(learning_rate)    \n",
    "    try:\n",
    "        details = {\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "\n",
    "        base_model = tf.keras.applications.DenseNet201(input_shape = (224, 224, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = True\n",
    "\n",
    "        global_average_layer = layers.GlobalAveragePooling2D()\n",
    "\n",
    "        classes_layer = layers.Dense(2, activation = 'sigmoid')\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            classes_layer,\n",
    "        ])\n",
    "\n",
    "        model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                      optimizer = tf.keras.optimizers.RMSprop(lr = learning_rate), #0.00000001\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"model_checkpoints/densenet201_\"+str(learning_rate)+\"{epoch:02d}.h5\",\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks = [checkpoint],\n",
    "                            verbose = 1)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Time Taken: {:0>2}:{:0>2}:{:05.3f}\".format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        model.save_weights(filepath = \"trained_models/densenet201_\"+str(learning_rate)+\".h5\")\n",
    "        pickle.dump(history.history, open(\"trained_models/densenet201_history_\"+str(learning_rate)+\".p\", \"wb\" ))\n",
    "    \n",
    "        details[\"model_path\"] = \"trained_models/densenet201_\"+str(learning_rate)+\".h5\"\n",
    "        details[\"history_path\"] = \"trained_models/densenet201_history_\"+str(learning_rate)+\".p\"\n",
    "        details[\"time_taken\"] = end-start\n",
    "        details[\"time_taken_hrs\"] = \"{:0>2}:{:0>2}:{:05.3f}\".format(int(hours),int(minutes),seconds)\n",
    "\n",
    "        densenet_models.append(details)\n",
    "        \n",
    "        df = pd.DataFrame(densenet_models)\n",
    "        df.to_csv(\"densenet_results.csv\", index = False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
